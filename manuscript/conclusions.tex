\section{Conclusion}
%%% Final considerations here

We have presented a comprehensive review of the strategies used to tackle the intensive computational cost associated with processing potential-field data using the equivalent-layer technique. 
Each of these strategies is rarely used  individually; rather, some 
developed equivalent-layer methods combine more than one strategy to achieve computational efficiency when dealing with large-scale data sets.
We focuses on  the following specific strategies: 
(1) the moving data-window scheme;
(2) the column-action and row-action updates;
(3) the sparsity induction of the sensitivity matrix;
(4) the reparametrization of the original parameters;
(5) the iterative scheme using the full sensitivity matrix;
(6) the iterative deconvolution; and
(7) the direct deconvolution.
Taking into account the mathematical bases used in the above-mentioned strategies, we have identified five groups:
i) the reduction of the dimensionality of the linear system of equations to be solved;
ii) the generation of a sparse linear system of equations to be solved;
iii) the explicit iterative method;
iv) the improvement in forward modeling; and
v) the deconvolution using the concept of block-Toeplitz Toeplitz-block (BTTB) matrices.

We show in this review that the computational cost of the equivalent layer can vary from up to $10^{9}$ flops depending on the method without compromising the linear system stability. 
The moving data-window scheme and direct deconvolution are the fastest methods; however, they both have drawbacks.
To be computationally efficient, the moving data-window scheme and 
the direct deconvolution require data and equivalent sources that are distributed on planar and regularly spaced grids.
Moreover, they both requires choosing an optimun parameter of stabilization. 
We stress that the direct deconvolution has an aditional disadvantage in terms of a higher data residual and border effects over the equivalent layer after processing.
These effects can be seen from the upward continuation of the real data from Caraj√°s.

We draw the readers' attention to the possibility of combining more than one aforementioned strategies for reducing the computational cost of the equivalent-layer technique.



%***** O TEXTO ABAIXO PERTENCE A VERSAO ANTERIOR DA CONCLUSAO ****
%From the above-mentioned strategies, further classifications may be identified %for reducing the computational cost of equivalent-layer technique. 
%For example, taking into account the mathematical bases, we identify five %groups:
%i)   the reduction of the dimensionality of the linear system of equations to %be solved;  
%ii)  the  generation of a sparse linear system of  equations to be solved; 
%iii) the explicity iterative method;
%iv)  the improvement in the forward modelling an;
%v) the convolution (deconvolution).

%The first mathematical basis reduces the linear system of equations to be solved for estimating the distribution over the equivalent layer.
%This is achieved by using diferent strategies: 
%a) the moving data-window scheme spanning the data by setting a small moving-data window;   
%b) the reduction of the dataset by selecting a subset of observations much smaller than the original data;
%c) the explicity reparametrization of the model (the equivalent layer) by using quadtree discretization or piecewise-polynomial functions defined on a set of equivalent-source windows and; 
%d) the implicity reparametrization of the model (the equivalent layer) by using the subspace method.
%
%The second mathematical basis generates a sparse linear system of equations 
%by transforming the full sensitivity matrix into a sparse one.
%This is achieved by using diferent strategies: 
%a) the compression of the coefficient of the sensitivity matrix via wavelet transforms and;
%b) the grouping of equivalent sources distant from an observation point to form a larger equivalent source via quadtree discretization of the equivalent layer;
%
%
%
%
%
%
%From the above-mentioned strategies, further classifications may be identified for reducing the computational cost of equivalent-layer technique. 
%For example, taking into account the mathematical bases, we identify four groups:
%i) the reduction of the dimensionality of the linear system of equations to be solved;  
%ii) the  generation of a sparse linear system of  equations to be solved; 
%iii) the explicity iterative method  without solving a linear system of equations and;
%iv) the convolution (deconvolution).
%The first mathematical basis reduces the linear system of equations to be solved for estimating the distribution over the equivalent layer.
%This is achieved by using diferent strategies: 
%a) the moving data-window scheme spanning the data set by setting a small moving-data window;   
%b) the reparametrization of the dataset by selecting a subset of observations much smaller than the original data;
%c) the explicity reparametrization of the model (the equivalent layer) by using quadtree discretization or piecewise-polynomial functions defined on a set of equivalent-source windows and; 
%d) the implicity reparametrization of the model (the equivalent layer) by using the subspace method. 
%The second mathematical basis generates a sparse linear system of equations 
%by transforming the full sensitivity matrix into a sparse one.
%This is achieved by using diferent strategies: 
%a) the compression of the coefficient of the sensitivity matrix via wavelet transforms and;
%b) the grouping of equivalent sources distant from an observation point to form a larger equivalent source via quadtree discretization of the equivalent layer;
%The third mathematical basis does not solve a linear system of equations
%for estimating the distribution over the equivalent layer.
%This is grounded on  gradient method as an optimization algorithm 
%that iteratively updates the parameter without calculating a full Hessian matrix and solving linear systems.
%This is achieved by using diferent strategies: 
%a) the conjugate gradient least-squares regularized by the number of iterations  with the sparse wavelet compression of the coefficient matrix;
%b) the iterative Landweber algorithm with forward modelling of potential-field data with Gauss-FFT;
%c) the gradient-boosting algorithm operating on overlapping windows with the block-averaged sources
%reduncing the number of the sources; and
%d) The explicit iterative method with (or not) physical reasoning without calculating a full Hessian matrix and solving linear systems
%The fourth mathematical basis for estimating the distribution over the equivalent layer is based on FFT convolution with the sensitivity matrices exhibiting BTTB structure when the observations and equivalent sources are aligned on a horizontal and regularly-spaced grid. 
%
%We would like to draw the readers' attention to the possibility of grouping the aforementioned strategies for reducing the computational cost of the equivalent-layer technique according to different mathematical bases.
%An example of the mathematical basis might be the reduction of the processing time spent on the forward modelling accounts. 
%
%
%
%
%%It is certainly impossible to include all references pertinent to
%%a comprehensive review such as this one in just a few pages.
%
